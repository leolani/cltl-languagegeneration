{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576fa53d-e66d-46ca-88ba-c045f954046d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24cdb01-94db-4ffd-8c21-5d90c651c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama3.2\"\n",
    "llama_model = ChatOllama(\n",
    "            model= model_name,\n",
    "            temperature=0.1,\n",
    "            # other params ...\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d57a488-ea80-4444-903b-0520a2860173",
   "metadata": {},
   "source": [
    "https://platform.openai.com/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d447c1e-b751-4a4b-b67f-bdf9f8a628d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UTTERANCE_TYPE = \"statement\"\n",
    "path = \"/Users/piek/Desktop/d-Leolani/cltl-languagegeneration/examples/data/basic-statements-responses.json\"\n",
    "#path = \"/Users/piek/Desktop/d-Leolani/cltl-languagegeneration/examples/data/basic-mentions-responses.json\"\n",
    "#UTTERANCE_TYPE = \"question\"\n",
    "#path = \"/Users/piek/Desktop/d-Leolani/cltl-languagegeneration/examples/data/basic-questions-responses.json\"\n",
    "file = open(path)\n",
    "data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6727286d-8ea4-4e4c-bf06-e7e6ef8959c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data 61\n",
      "response\n",
      "statement\n",
      "thoughts\n",
      "rdf_log_path\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of data\", len(data))\n",
    "for item in data:\n",
    "    for el in item:\n",
    "        print(el)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3198fa-a515-4d17-88a0-1db767151273",
   "metadata": {},
   "source": [
    "thoughts-responses is a list of responses. Each response has the following data elements:\n",
    "\n",
    "* response: id\n",
    "* statement: the statement to which a response is created with\n",
    "* thoughts: the thoughts\n",
    "* rdf_log_path\n",
    "\n",
    "The statement consists of:\n",
    "\n",
    "* chat\n",
    "* turn\n",
    "* author, \n",
    "* utterance, \n",
    "* subject, \n",
    "* predicate, \n",
    "* object\n",
    "* perspective\n",
    "* timestamp\n",
    "* context_id\n",
    "* triple (_subject, _predicate, _complement)\n",
    "\n",
    "The thoughts is a list of the elements:\n",
    "\n",
    "* _statement_novelty\n",
    "* _entity_novelty\n",
    "* _negation_conflicts\n",
    "* _complement_conflict\n",
    "* _subject_gaps\n",
    "* _complement_gaps\n",
    "* _overlaps\n",
    "* _trust\n",
    "\n",
    "For each thought, we need to formulate a different prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7099c907-fec4-4897-916b-84b1ff662f67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat\n",
      "turn\n",
      "author\n",
      "utterance\n",
      "utterance_type\n",
      "position\n",
      "subject\n",
      "predicate\n",
      "object\n",
      "perspective\n",
      "timestamp\n",
      "context_id\n",
      "triple\n"
     ]
    }
   ],
   "source": [
    "### Get all statement from data\n",
    "statements = []\n",
    "for response in data:\n",
    "    statements.append(response[\"statement\"])\n",
    "for item in statements[0]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a33b712-9d70-43dc-908e-4751e8d560d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_triple_text_from_statement (statement):\n",
    "    triple = statement[\"triple\"]\n",
    "    triple_text = triple[\"_subject\"][\"_label\"]+\", \"+triple[\"_predicate\"][\"_label\"]+\", \"+triple[\"_complement\"][\"_label\"]\n",
    "    return triple_text\n",
    "\n",
    "def get_perspective_from_statement  (statement):\n",
    "    perspective = statement[\"perspective\"]\n",
    "    perspective_text = \"\"\n",
    "    if not perspective['_certainty']=='UNDERSPECIFIED':\n",
    "        perspective_text += perspective['_certainty']+ \", \"\n",
    "    if perspective['_polarity']=='POSITIVE':\n",
    "        perspective_text += 'believes'+ \", \"\n",
    "    elif perspective['_polarity']=='NEGATIVE':\n",
    "        perspective_text += 'denies'+ \", \"\n",
    "    if not perspective['_sentiment']=='NEUTRAL':\n",
    "        perspective_text += perspective['_sentiment']+ \", \"\n",
    "    if not perspective['_emotion']=='UNDERSPECIFIED':\n",
    "        perspective_text += perspective['_emotion']+ \", \"\n",
    "    return perspective_text\n",
    "\n",
    "def get_source_from_statement (statement):\n",
    "    #\"author\": {\"label\": \"piek\"\n",
    "    author = statement[\"author\"][\"label\"]\n",
    "    return author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "367f0b94-d7a0-49c7-98c6-3da5169904f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_subject': {'_id': 'http://cltl.nl/leolani/world/lenka-1', '_label': 'lenka', '_offset': None, '_confidence': 0.0, '_types': ['person', 'Instance']}, '_predicate': {'_id': 'http://cltl.nl/leolani/n2mu/be-from', '_label': 'be-from', '_offset': None, '_confidence': 0.0, '_cardinality': 1}, '_complement': {'_id': 'http://cltl.nl/leolani/world/serbia', '_label': 'serbia', '_offset': None, '_confidence': 0.0, '_types': ['location', 'Instance']}}\n",
      "lenka be-from serbia\n",
      "{'_certainty': 'CERTAIN', '_polarity': 'POSITIVE', '_sentiment': 'NEUTRAL', '_time': None, '_emotion': 'UNDERSPECIFIED'}\n"
     ]
    }
   ],
   "source": [
    "triple = statements[0][\"triple\"]\n",
    "print(triple)\n",
    "triple_text = triple[\"_subject\"][\"_label\"]+\" \"+triple[\"_predicate\"][\"_label\"]+\" \"+triple[\"_complement\"][\"_label\"]\n",
    "print(triple_text)\n",
    "perspective = statements[0][\"perspective\"]\n",
    "print(perspective)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847cc5d9-2f8c-4df2-87e3-6ba51b2dc13f",
   "metadata": {},
   "source": [
    "### Instruct-1\n",
    "\n",
    "Paraphrases triples and author perspectives expressed through a that-phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fe44fb1-f21e-4593-ba77-b4b9e088adff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UTTERANCE_TYPE = \"statement\"\n",
    "\n",
    "instruct_1_triples_perspectives = {\"role\": \"system\", \"content\": f\"You are an intelligent assistant. \\\n",
    "     I will give you as input: a phrase, followed by a perspective, followed by \\\"that\\\" and a triple with a subject, predicate and object.\\\n",
    "     You need to paraphrase the input in plain English as a {UTTERANCE_TYPE} and express both author perspective and the triple information. \\\n",
    "     Only reply with the short paraphrase of the input. \\\n",
    "     Do not give an explanation. \\\n",
    "     Do not explain what the subject and object is. \\\n",
    "     The response should be just the paraphrased text and nothing else.\"\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da33d93b-b1c6-4f46-b4ba-417beb2827f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/piek/Desktop/d-Leolani/cltl-languagegeneration/examples/data/basic-statements-responses.json\n",
      "\n",
      "Triple text lenka, be-from, serbia\n",
      "perspective_text CERTAIN, believes, \n",
      "author piek\n",
      "Generated output Piek is certain that Lenka is from Serbia.\n",
      "\n",
      "Triple text bram, be-from, netherlands\n",
      "perspective_text CERTAIN, believes, \n",
      "author piek\n",
      "Generated output Bram is from the Netherlands.\n",
      "\n",
      "Triple text selene, be-from, mexico\n",
      "perspective_text CERTAIN, believes, \n",
      "author piek\n",
      "Generated output Piek is certain that Selene was born in Mexico.\n",
      "\n",
      "Triple text suzana, be-from, croatia\n",
      "perspective_text CERTAIN, believes, \n",
      "author piek\n",
      "Generated output Suzana is from Croatia.\n",
      "\n",
      "Triple text selene, be-from, netherlands\n",
      "perspective_text CERTAIN, believes, \n",
      "author piek\n",
      "Generated output Piek from Netherlands is certain that Selene is from there.\n",
      "\n",
      "Triple text lenka, be-from, serbia\n",
      "perspective_text PROBABLE, believes, \n",
      "author selene\n",
      "Generated output Selene probably believes Lenka is from Serbia.\n",
      "\n",
      "Triple text bram, like, goulash\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author selene\n",
      "Generated output Selene is certain about Bram liking goulash.\n",
      "\n",
      "Triple text bram, like, romantic-movies\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author selene\n",
      "Generated output Selene is certain that Bram likes romantic movies.\n",
      "\n",
      "Triple text lenka, like, ice-cream\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author selene\n",
      "Generated output Selene is very confident that Lenka loves ice cream.\n",
      "\n",
      "Triple text lenka, like, harry-potter\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author selene\n",
      "Generated output Selene is very confident in her opinion that Lenka has qualities similar to Harry Potter.\n",
      "\n",
      "Triple text lenka, like, action-movies\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author selene\n",
      "Generated output Selene is certain about Lenka's preference for action movies.\n",
      "\n",
      "Triple text piek, like, balkenbrij\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author selene\n",
      "Generated output Selene is certain about Piek being like Balkenbrij.\n",
      "\n",
      "Triple text piek, like, sailing\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author selene\n",
      "Generated output Selene is certain that Piek enjoys sailing.\n",
      "\n",
      "Triple text selene, like, tacos\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author selene\n",
      "Generated output Selene is very confident in her opinion that she loves tacos.\n",
      "\n",
      "Triple text suzana, like, pizza\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author selene\n",
      "Generated output Selena strongly believes that Suzana loves pizza.\n",
      "\n",
      "Triple text leolani, be-from, france\n",
      "perspective_text CERTAIN, believes, \n",
      "author selene\n",
      "Generated output Selene is certain that Leolani was born in France.\n",
      "\n",
      "Triple text lenka, mother-is, ljubica\n",
      "perspective_text CERTAIN, believes, \n",
      "author lenka\n",
      "Generated output Lenka's mother is certain that Lenka is her daughter, LJUBICA.\n",
      "\n",
      "Triple text lenka, love, cake\n",
      "perspective_text CERTAIN, believes, \n",
      "author lenka\n",
      "Generated output Lenka is certain that she loves cake.\n",
      "\n",
      "Triple text selene, like, coco\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author lenka\n",
      "Generated output Lenka is very confident in her opinion that Selene is similar to Coco.\n",
      "\n",
      "Triple text bram, like, the-big-lebowski\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author lenka\n",
      "Generated output Lenka is very confident in her opinion that Bram is a big fan of The Big Lebowski.\n",
      "\n",
      "Triple text piek, like, 2001-a-space-odyssey\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author lenka\n",
      "Generated output Lenka is very sure that she likes the movie \"2001: A Space Odyssey\".\n",
      "\n",
      "Triple text piek, like, horror-movies\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author lenka\n",
      "Generated output Lenka is very sure that she enjoys watching horror movies.\n",
      "\n",
      "Triple text bram, like, action-movies\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author bram\n",
      "Generated output Bram strongly agrees with himself that he enjoys action movies.\n",
      "\n",
      "Triple text bram, be-from, italy\n",
      "perspective_text CERTAIN, believes, \n",
      "author bram\n",
      "Generated output Bram is certain that he is from Italy.\n",
      "\n",
      "Triple text bram, like, goulash\n",
      "perspective_text CERTAIN, denies, NEGATIVE, \n",
      "author bram\n",
      "Generated output Bram strongly believes he doesn't like goulash.\n",
      "\n",
      "Triple text bram, like, baseball\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author bram\n",
      "Generated output Bram is very confident in his love for baseball.\n",
      "\n",
      "Triple text bram, like, apple-pie\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author bram\n",
      "Generated output Bram strongly agrees with himself that he loves apple pie.\n",
      "\n",
      "Triple text selene, like, animated-movies\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author bram\n",
      "Generated output Bram strongly believes that Selene enjoys watching animated movies.\n",
      "\n",
      "Triple text lenka, like, acrobatics\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author bram\n",
      "Generated output Bram strongly believes that Lenka has a talent for acrobatics.\n",
      "\n",
      "Triple text leolani, manufacture-in, japan\n",
      "perspective_text CERTAIN, believes, \n",
      "author bram\n",
      "Generated output Bram is certain that Leolani manufactures products in Japan.\n",
      "\n",
      "Triple text bram, like, romantic-movies\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author piek\n",
      "Generated output Bram loves romantic movies.\n",
      "\n",
      "Triple text selene, like, tacos\n",
      "perspective_text CERTAIN, denies, NEGATIVE, \n",
      "author piek\n",
      "Generated output Piek is certain that Selene likes tacos.\n",
      "\n",
      "Triple text piek, like, tacos\n",
      "perspective_text CERTAIN, believes, NEGATIVE, \n",
      "author piek\n",
      "Generated output Piek doesn't think tacos are good.\n",
      "\n",
      "Triple text bram, be-from, netherlands\n",
      "perspective_text CERTAIN, denies, \n",
      "author suzana\n",
      "Generated output Suzana is certain that Bram is from the Netherlands.\n",
      "\n",
      "Triple text piek, be-from, netherlands\n",
      "perspective_text CERTAIN, believes, \n",
      "author suzana\n",
      "Generated output Suzana is certain that Piek is from the Netherlands.\n",
      "\n",
      "Triple text selene, like, soccer\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author suzana\n",
      "Generated output Suzana is very confident that Selene enjoys playing soccer.\n",
      "\n",
      "Triple text bram, know, lenka\n",
      "perspective_text CERTAIN, believes, \n",
      "author suzana\n",
      "Generated output Suzana is certain that Bram knows Lenka.\n",
      "\n",
      "Triple text selene, know, lenka\n",
      "perspective_text CERTAIN, believes, \n",
      "author suzana\n",
      "Generated output Suzana is certain that Lenka knows Selene.\n",
      "\n",
      "Triple text selene, be-from, peru\n",
      "perspective_text PROBABLE, believes, \n",
      "author lenka\n",
      "Generated output Lenka thinks she's from Peru.\n",
      "\n",
      "Triple text jaap, have, teapot\n",
      "perspective_text PROBABLE, believes, \n",
      "author lea\n",
      "Generated output Lea thinks Jaap has a teapot.\n",
      "\n",
      "Triple text lea, love, blue\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author lea\n",
      "Generated output Lea truly loves blue with certainty.\n",
      "\n",
      "Triple text selene, be, tall\n",
      "perspective_text POSSIBLE, believes, \n",
      "author lea\n",
      "Generated output Lea thinks Selene is tall because she can be.\n",
      "\n",
      "Triple text lea, like, swimming-and-biking\n",
      "perspective_text PROBABLE, believes, POSITIVE, \n",
      "author lea\n",
      "Generated output Lea thinks she's very good at swimming and biking.\n",
      "\n",
      "Triple text lea, be-from, dusseldorf\n",
      "perspective_text CERTAIN, believes, \n",
      "author lea\n",
      "Generated output Lea is certain that she is from DÃ¼sseldorf.\n",
      "\n",
      "Triple text lea, like, celery\n",
      "perspective_text PROBABLE, denies, NEGATIVE, \n",
      "author lea\n",
      "Generated output Lea probably doesn't deny something negative about celery.\n",
      "\n",
      "Triple text thomas, live-in, berlin\n",
      "perspective_text CERTAIN, believes, \n",
      "author thomas\n",
      "Generated output Thomas lives in Berlin.\n",
      "\n",
      "Triple text thomas, be-from, munich\n",
      "perspective_text CERTAIN, believes, \n",
      "author thomas\n",
      "Generated output Thomas is certain that he is from Munich.\n",
      "\n",
      "Triple text thomas, study-in, budapest\n",
      "perspective_text CERTAIN, believes, \n",
      "author thomas\n",
      "Generated output Thomas is certain that he studies in Budapest.\n",
      "\n",
      "Triple text thomas, like, asian-food\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author thomas\n",
      "Generated output Thomas strongly believes in trying Asian food.\n",
      "\n",
      "Triple text thomas, like, electronic-music\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author thomas\n",
      "Generated output Thomas strongly believes that Thomas enjoys electronic music.\n",
      "\n",
      "Triple text lea, hate, cheese\n",
      "perspective_text PROBABLE, believes, NEGATIVE, \n",
      "author jaap\n",
      "Generated output Jaap probably hates cheese because he believes it's negative.\n",
      "\n",
      "Triple text selene, like, dancing\n",
      "perspective_text PROBABLE, believes, POSITIVE, \n",
      "author jaap\n",
      "Generated output Jaap thinks Selene is likely to be dancing.\n",
      "\n",
      "Triple text jaap, have, two-teapots\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author jaap\n",
      "Generated output Jaap is certain that Jaap has two teapots.\n",
      "\n",
      "Triple text jaap, like, chocolate-with-sea-salt\n",
      "perspective_text CERTAIN, denies, \n",
      "author jaap\n",
      "Generated output Jaap is certain about his dislike for chocolate with sea salt.\n",
      "\n",
      "Triple text lea, like, swimming-and-vikings\n",
      "perspective_text POSSIBLE, believes, POSITIVE, \n",
      "author jaap\n",
      "Generated output Jaap thinks Lea is a great person who enjoys swimming and Vikings.\n",
      "\n",
      "Triple text tae, speak, german\n",
      "perspective_text CERTAIN, believes, \n",
      "author jaap\n",
      "Generated output Jaap is certain that Tae speaks German.\n",
      "\n",
      "Triple text tae, like, drinking-beer\n",
      "perspective_text CERTAIN, believes, POSITIVE, \n",
      "author tae\n",
      "Generated output Tae is certain about his decision to drink beer.\n",
      "\n",
      "Triple text tae, be-from, south-korea\n",
      "perspective_text CERTAIN, believes, \n",
      "author tae\n",
      "Generated output Tae is certain that Tae is from South Korea.\n",
      "\n",
      "Triple text tae, ride, bike\n",
      "perspective_text CERTAIN, believes, \n",
      "author tae\n",
      "Generated output Tae is certain that tae will ride a bike.\n",
      "\n",
      "Triple text tae, hate, rats\n",
      "perspective_text CERTAIN, believes, NEGATIVE, \n",
      "author tae\n",
      "Generated output Tae strongly disagrees with someone who believes that tae hates rats.\n",
      "\n",
      "Triple text tae, drink, beer\n",
      "perspective_text CERTAIN, denies, \n",
      "author tae\n",
      "Generated output Tae is certain that tae denies drinking beer.\n"
     ]
    }
   ],
   "source": [
    "print(path)\n",
    "for statement in statements:\n",
    "    triple = statement[\"triple\"]\n",
    "    triple_text = get_triple_text_from_statement(statement)\n",
    "    perspective = statement[\"perspective\"]\n",
    "    perspective_text = get_perspective_from_statement(statement)\n",
    "    author = get_source_from_statement(statement)\n",
    "    prompt = [instruct_1_triples_perspectives, {\"role\": \"user\", \"content\": author + \" is \"+ perspective_text+ \" that \"+ triple_text}]\n",
    "    response = llama_model.invoke(prompt)\n",
    "    print()\n",
    "    print('Triple text', triple_text)\n",
    "    print('perspective_text', perspective_text)\n",
    "    print('author', author)\n",
    "    print('Generated output', response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13a9ab-5fbd-45c0-9992-a370345bb981",
   "metadata": {},
   "source": [
    "# OTHER PROMPT ATTEMPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a70f2-bb40-4ab3-a687-4d0775de2022",
   "metadata": {},
   "source": [
    "### Instruct-2\n",
    "\n",
    "Simpler version to paraphrase triples and author perspectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b12d6d88-aabd-4872-b316-9e0d7f70f585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruct_2_triples_perspectives = {\"role\": \"system\", \"content\": f\"You are an intelligent assistant. \\\n",
    "     I will give you a phrase, followed by a perspective and a triple with a subject, predicate and object that you need to paraphrase in plain English as a {UTTERANCE_TYPE}. \\\n",
    "     Do not give an explanation, only reply with a short paraphrase of the input and spell the subject and object names as given. \"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a2581-d051-4924-8f93-5d81e34d3dee",
   "metadata": {},
   "source": [
    "### Instruct-3\n",
    "\n",
    "Praphrases triples and not perspectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3ab9610-d2fb-43d2-80e4-028e5727218f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruct_3_triples = {\"role\": \"system\", \"content\": f\"You are an intelligent assistant. \\\n",
    "     I will give you a triple with a subject, predicate and object that you need to paraphrase in plain English as a {UTTERANCE_TYPE}. \\\n",
    "     Do not give an explanation or comment, just paraphrase as a short statement and spell the subject and object labels exactly as given but you may capitalize them if it is a name. \\\n",
    "     Do not comment on the capitalization.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59e919e-d5d3-420a-b6fb-31be7d468bc1",
   "metadata": {},
   "source": [
    "### Instruct-4 subject gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d330f25a-e5d2-4f2a-a4e7-9c3bd825f6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is this person from Serbia?\n"
     ]
    }
   ],
   "source": [
    "UTTERANCE_TYPE = \"question\"\n",
    "instruct_4_subject_gap = {\"role\": \"system\", \"content\": f\"You are an intelligent assistant. \\\n",
    "     I will give you as input: a triple with a predicate and object that lacks a subject.\\\n",
    "     You need to paraphrase the input in plain English as a {UTTERANCE_TYPE}. \\\n",
    "     Only reply with the short paraphrase of the input. \\\n",
    "     Do not give an explanation. \\\n",
    "     Do not explain what the subject and object is. \\\n",
    "     The response should be just the paraphrased text and nothing else.\"\n",
    "           }\n",
    "\n",
    "triple_text = \"be-from Serbia\"\n",
    "\n",
    "prompt = [instruct_4_subject_gap, {\"role\": \"user\", \"content\": triple_text}]\n",
    "   # prompt.append({\"role\": \"user\", \"content\": triple_text})\n",
    "response = llama_model.invoke(prompt)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd199cce-78a1-43fb-820a-f617b4f53364",
   "metadata": {},
   "source": [
    "## Instruct-5 object gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9aa19a5f-ce89-40ea-b162-4ea73a72ae19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where are you from?\n"
     ]
    }
   ],
   "source": [
    "UTTERANCE_TYPE = \"question\"\n",
    "instruct_5_object_gap = {\"role\": \"system\", \"content\": f\"You are an intelligent assistant. \\\n",
    "     I will give you as input: a triple with a subject, a predicate and a type of object.\\\n",
    "     You need to paraphrase the input in plain English as a {UTTERANCE_TYPE} for the object. \\\n",
    "     Use who for the type person, where for the type location, when for the type time and what for everything else. \\\n",
    "     Only reply with the short paraphrase of the input. \\\n",
    "     Do not give an explanation. \\\n",
    "     Do not explain what the subject and object is. \\\n",
    "     The response should be just the paraphrased text and nothing else.\"\n",
    "           }\n",
    "\n",
    "triple_text = \"Lenka be-from location\"\n",
    "\n",
    "prompt = [instruct_5_object_gap, {\"role\": \"user\", \"content\": triple_text}]\n",
    "   # prompt.append({\"role\": \"user\", \"content\": triple_text})\n",
    "response = llama_model.invoke(prompt)\n",
    "print(response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc62d0-60ad-4aaa-be2d-837f5ce849e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
